{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28395</td>\n",
       "      <td>610.291</td>\n",
       "      <td>208.178117</td>\n",
       "      <td>173.888747</td>\n",
       "      <td>1.197191</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>28715</td>\n",
       "      <td>190.141097</td>\n",
       "      <td>0.763923</td>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.958027</td>\n",
       "      <td>0.913358</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28734</td>\n",
       "      <td>638.018</td>\n",
       "      <td>200.524796</td>\n",
       "      <td>182.734419</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>0.411785</td>\n",
       "      <td>29172</td>\n",
       "      <td>191.272751</td>\n",
       "      <td>0.783968</td>\n",
       "      <td>0.984986</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29380</td>\n",
       "      <td>624.110</td>\n",
       "      <td>212.826130</td>\n",
       "      <td>175.931143</td>\n",
       "      <td>1.209713</td>\n",
       "      <td>0.562727</td>\n",
       "      <td>29690</td>\n",
       "      <td>193.410904</td>\n",
       "      <td>0.778113</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>0.908774</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30008</td>\n",
       "      <td>645.884</td>\n",
       "      <td>210.557999</td>\n",
       "      <td>182.516516</td>\n",
       "      <td>1.153638</td>\n",
       "      <td>0.498616</td>\n",
       "      <td>30724</td>\n",
       "      <td>195.467062</td>\n",
       "      <td>0.782681</td>\n",
       "      <td>0.976696</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30140</td>\n",
       "      <td>620.134</td>\n",
       "      <td>201.847882</td>\n",
       "      <td>190.279279</td>\n",
       "      <td>1.060798</td>\n",
       "      <td>0.333680</td>\n",
       "      <td>30417</td>\n",
       "      <td>195.896503</td>\n",
       "      <td>0.773098</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13606</th>\n",
       "      <td>42097</td>\n",
       "      <td>759.696</td>\n",
       "      <td>288.721612</td>\n",
       "      <td>185.944705</td>\n",
       "      <td>1.552728</td>\n",
       "      <td>0.765002</td>\n",
       "      <td>42508</td>\n",
       "      <td>231.515799</td>\n",
       "      <td>0.714574</td>\n",
       "      <td>0.990331</td>\n",
       "      <td>0.916603</td>\n",
       "      <td>0.801865</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.642988</td>\n",
       "      <td>0.998385</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>42101</td>\n",
       "      <td>757.499</td>\n",
       "      <td>281.576392</td>\n",
       "      <td>190.713136</td>\n",
       "      <td>1.476439</td>\n",
       "      <td>0.735702</td>\n",
       "      <td>42494</td>\n",
       "      <td>231.526798</td>\n",
       "      <td>0.799943</td>\n",
       "      <td>0.990752</td>\n",
       "      <td>0.922015</td>\n",
       "      <td>0.822252</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.676099</td>\n",
       "      <td>0.998219</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>42139</td>\n",
       "      <td>759.321</td>\n",
       "      <td>281.539928</td>\n",
       "      <td>191.187979</td>\n",
       "      <td>1.472582</td>\n",
       "      <td>0.734065</td>\n",
       "      <td>42569</td>\n",
       "      <td>231.631261</td>\n",
       "      <td>0.729932</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.918424</td>\n",
       "      <td>0.822730</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.676884</td>\n",
       "      <td>0.996767</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>42147</td>\n",
       "      <td>763.779</td>\n",
       "      <td>283.382636</td>\n",
       "      <td>190.275731</td>\n",
       "      <td>1.489326</td>\n",
       "      <td>0.741055</td>\n",
       "      <td>42667</td>\n",
       "      <td>231.653247</td>\n",
       "      <td>0.705389</td>\n",
       "      <td>0.987813</td>\n",
       "      <td>0.907906</td>\n",
       "      <td>0.817457</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.668237</td>\n",
       "      <td>0.995222</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13610</th>\n",
       "      <td>42159</td>\n",
       "      <td>772.237</td>\n",
       "      <td>295.142741</td>\n",
       "      <td>182.204716</td>\n",
       "      <td>1.619841</td>\n",
       "      <td>0.786693</td>\n",
       "      <td>42600</td>\n",
       "      <td>231.686223</td>\n",
       "      <td>0.788962</td>\n",
       "      <td>0.989648</td>\n",
       "      <td>0.888380</td>\n",
       "      <td>0.784997</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.616221</td>\n",
       "      <td>0.998180</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13611 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0      28395    610.291       208.178117       173.888747      1.197191   \n",
       "1      28734    638.018       200.524796       182.734419      1.097356   \n",
       "2      29380    624.110       212.826130       175.931143      1.209713   \n",
       "3      30008    645.884       210.557999       182.516516      1.153638   \n",
       "4      30140    620.134       201.847882       190.279279      1.060798   \n",
       "...      ...        ...              ...              ...           ...   \n",
       "13606  42097    759.696       288.721612       185.944705      1.552728   \n",
       "13607  42101    757.499       281.576392       190.713136      1.476439   \n",
       "13608  42139    759.321       281.539928       191.187979      1.472582   \n",
       "13609  42147    763.779       283.382636       190.275731      1.489326   \n",
       "13610  42159    772.237       295.142741       182.204716      1.619841   \n",
       "\n",
       "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "0          0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
       "1          0.411785       29172     191.272751  0.783968  0.984986   0.887034   \n",
       "2          0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
       "3          0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
       "4          0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
       "...             ...         ...            ...       ...       ...        ...   \n",
       "13606      0.765002       42508     231.515799  0.714574  0.990331   0.916603   \n",
       "13607      0.735702       42494     231.526798  0.799943  0.990752   0.922015   \n",
       "13608      0.734065       42569     231.631261  0.729932  0.989899   0.918424   \n",
       "13609      0.741055       42667     231.653247  0.705389  0.987813   0.907906   \n",
       "13610      0.786693       42600     231.686223  0.788962  0.989648   0.888380   \n",
       "\n",
       "       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
       "0         0.913358      0.007332      0.003147      0.834222      0.998724   \n",
       "1         0.953861      0.006979      0.003564      0.909851      0.998430   \n",
       "2         0.908774      0.007244      0.003048      0.825871      0.999066   \n",
       "3         0.928329      0.007017      0.003215      0.861794      0.994199   \n",
       "4         0.970516      0.006697      0.003665      0.941900      0.999166   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "13606     0.801865      0.006858      0.001749      0.642988      0.998385   \n",
       "13607     0.822252      0.006688      0.001886      0.676099      0.998219   \n",
       "13608     0.822730      0.006681      0.001888      0.676884      0.996767   \n",
       "13609     0.817457      0.006724      0.001852      0.668237      0.995222   \n",
       "13610     0.784997      0.007001      0.001640      0.616221      0.998180   \n",
       "\n",
       "          Class  \n",
       "0         SEKER  \n",
       "1         SEKER  \n",
       "2         SEKER  \n",
       "3         SEKER  \n",
       "4         SEKER  \n",
       "...         ...  \n",
       "13606  DERMASON  \n",
       "13607  DERMASON  \n",
       "13608  DERMASON  \n",
       "13609  DERMASON  \n",
       "13610  DERMASON  \n",
       "\n",
       "[13611 rows x 17 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Dry_Bean_Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 1, 2, 4, 6, 3])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "  \n",
    "# label_encoder object knows  \n",
    "# how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "df['Class']= label_encoder.fit_transform(df['Class']) \n",
    "  \n",
    "df['Class'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5\n",
       "1        5\n",
       "2        5\n",
       "3        5\n",
       "4        5\n",
       "        ..\n",
       "13606    3\n",
       "13607    3\n",
       "13608    3\n",
       "13609    3\n",
       "13610    3\n",
       "Name: Class, Length: 13611, dtype: int32"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.concat([X_train,y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10704</th>\n",
       "      <td>27490</td>\n",
       "      <td>618.868</td>\n",
       "      <td>233.001523</td>\n",
       "      <td>151.202562</td>\n",
       "      <td>1.540989</td>\n",
       "      <td>0.760845</td>\n",
       "      <td>27753</td>\n",
       "      <td>187.086491</td>\n",
       "      <td>0.731117</td>\n",
       "      <td>0.990524</td>\n",
       "      <td>0.901963</td>\n",
       "      <td>0.802941</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.644714</td>\n",
       "      <td>0.993498</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13145</th>\n",
       "      <td>37946</td>\n",
       "      <td>738.476</td>\n",
       "      <td>264.960115</td>\n",
       "      <td>182.588263</td>\n",
       "      <td>1.451134</td>\n",
       "      <td>0.724651</td>\n",
       "      <td>38540</td>\n",
       "      <td>219.805250</td>\n",
       "      <td>0.759224</td>\n",
       "      <td>0.984587</td>\n",
       "      <td>0.874386</td>\n",
       "      <td>0.829579</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.688201</td>\n",
       "      <td>0.998672</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>67686</td>\n",
       "      <td>1044.470</td>\n",
       "      <td>368.601069</td>\n",
       "      <td>234.202503</td>\n",
       "      <td>1.573856</td>\n",
       "      <td>0.772198</td>\n",
       "      <td>69063</td>\n",
       "      <td>293.565141</td>\n",
       "      <td>0.708383</td>\n",
       "      <td>0.980062</td>\n",
       "      <td>0.779681</td>\n",
       "      <td>0.796431</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.634302</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>74759</td>\n",
       "      <td>1058.713</td>\n",
       "      <td>405.850888</td>\n",
       "      <td>238.557776</td>\n",
       "      <td>1.701269</td>\n",
       "      <td>0.809009</td>\n",
       "      <td>76604</td>\n",
       "      <td>308.522471</td>\n",
       "      <td>0.751037</td>\n",
       "      <td>0.975915</td>\n",
       "      <td>0.838141</td>\n",
       "      <td>0.760187</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.577884</td>\n",
       "      <td>0.983136</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12624</th>\n",
       "      <td>35110</td>\n",
       "      <td>693.189</td>\n",
       "      <td>254.183543</td>\n",
       "      <td>176.478601</td>\n",
       "      <td>1.440308</td>\n",
       "      <td>0.719690</td>\n",
       "      <td>35528</td>\n",
       "      <td>211.431881</td>\n",
       "      <td>0.765925</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.918200</td>\n",
       "      <td>0.831808</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.691904</td>\n",
       "      <td>0.996555</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>37832</td>\n",
       "      <td>720.476</td>\n",
       "      <td>263.034496</td>\n",
       "      <td>183.384981</td>\n",
       "      <td>1.434330</td>\n",
       "      <td>0.716887</td>\n",
       "      <td>38289</td>\n",
       "      <td>219.474824</td>\n",
       "      <td>0.725168</td>\n",
       "      <td>0.988064</td>\n",
       "      <td>0.915862</td>\n",
       "      <td>0.834396</td>\n",
       "      <td>0.006953</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.696216</td>\n",
       "      <td>0.998603</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>85890</td>\n",
       "      <td>1152.016</td>\n",
       "      <td>417.536420</td>\n",
       "      <td>262.719645</td>\n",
       "      <td>1.589285</td>\n",
       "      <td>0.777232</td>\n",
       "      <td>87188</td>\n",
       "      <td>330.694035</td>\n",
       "      <td>0.714654</td>\n",
       "      <td>0.985113</td>\n",
       "      <td>0.813271</td>\n",
       "      <td>0.792012</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.627284</td>\n",
       "      <td>0.996933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>51131</td>\n",
       "      <td>842.796</td>\n",
       "      <td>316.185621</td>\n",
       "      <td>207.028992</td>\n",
       "      <td>1.527253</td>\n",
       "      <td>0.755828</td>\n",
       "      <td>51654</td>\n",
       "      <td>255.150958</td>\n",
       "      <td>0.812506</td>\n",
       "      <td>0.989875</td>\n",
       "      <td>0.904585</td>\n",
       "      <td>0.806966</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.651194</td>\n",
       "      <td>0.994537</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>27884</td>\n",
       "      <td>630.303</td>\n",
       "      <td>239.405409</td>\n",
       "      <td>148.484842</td>\n",
       "      <td>1.612322</td>\n",
       "      <td>0.784425</td>\n",
       "      <td>28196</td>\n",
       "      <td>188.422428</td>\n",
       "      <td>0.758253</td>\n",
       "      <td>0.988935</td>\n",
       "      <td>0.881995</td>\n",
       "      <td>0.787043</td>\n",
       "      <td>0.008586</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.619437</td>\n",
       "      <td>0.998732</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>70344</td>\n",
       "      <td>1037.985</td>\n",
       "      <td>378.651095</td>\n",
       "      <td>237.909773</td>\n",
       "      <td>1.591574</td>\n",
       "      <td>0.777964</td>\n",
       "      <td>71521</td>\n",
       "      <td>299.273725</td>\n",
       "      <td>0.821354</td>\n",
       "      <td>0.983543</td>\n",
       "      <td>0.820455</td>\n",
       "      <td>0.790368</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.624682</td>\n",
       "      <td>0.994227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9527 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "10704  27490    618.868       233.001523       151.202562      1.540989   \n",
       "13145  37946    738.476       264.960115       182.588263      1.451134   \n",
       "2571   67686   1044.470       368.601069       234.202503      1.573856   \n",
       "4683   74759   1058.713       405.850888       238.557776      1.701269   \n",
       "12624  35110    693.189       254.183543       176.478601      1.440308   \n",
       "...      ...        ...              ...              ...           ...   \n",
       "13123  37832    720.476       263.034496       183.384981      1.434330   \n",
       "3264   85890   1152.016       417.536420       262.719645      1.589285   \n",
       "9845   51131    842.796       316.185621       207.028992      1.527253   \n",
       "10799  27884    630.303       239.405409       148.484842      1.612322   \n",
       "2732   70344   1037.985       378.651095       237.909773      1.591574   \n",
       "\n",
       "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "10704      0.760845       27753     187.086491  0.731117  0.990524   0.901963   \n",
       "13145      0.724651       38540     219.805250  0.759224  0.984587   0.874386   \n",
       "2571       0.772198       69063     293.565141  0.708383  0.980062   0.779681   \n",
       "4683       0.809009       76604     308.522471  0.751037  0.975915   0.838141   \n",
       "12624      0.719690       35528     211.431881  0.765925  0.988235   0.918200   \n",
       "...             ...         ...            ...       ...       ...        ...   \n",
       "13123      0.716887       38289     219.474824  0.725168  0.988064   0.915862   \n",
       "3264       0.777232       87188     330.694035  0.714654  0.985113   0.813271   \n",
       "9845       0.755828       51654     255.150958  0.812506  0.989875   0.904585   \n",
       "10799      0.784425       28196     188.422428  0.758253  0.988935   0.881995   \n",
       "2732       0.777964       71521     299.273725  0.821354  0.983543   0.820455   \n",
       "\n",
       "       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
       "10704     0.802941      0.008476      0.002173      0.644714      0.993498   \n",
       "13145     0.829579      0.006983      0.002040      0.688201      0.998672   \n",
       "2571      0.796431      0.005446      0.001352      0.634302      0.998299   \n",
       "4683      0.760187      0.005429      0.001118      0.577884      0.983136   \n",
       "12624     0.831808      0.007240      0.002138      0.691904      0.996555   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "13123     0.834396      0.006953      0.002079      0.696216      0.998603   \n",
       "3264      0.792012      0.004861      0.001180      0.627284      0.996933   \n",
       "9845      0.806966      0.006184      0.001618      0.651194      0.994537   \n",
       "10799     0.787043      0.008586      0.002032      0.619437      0.998732   \n",
       "2732      0.790368      0.005383      0.001296      0.624682      0.994227   \n",
       "\n",
       "       Class  \n",
       "10704      3  \n",
       "13145      3  \n",
       "2571       0  \n",
       "4683       2  \n",
       "12624      3  \n",
       "...      ...  \n",
       "13123      3  \n",
       "3264       0  \n",
       "9845       6  \n",
       "10799      3  \n",
       "2732       0  \n",
       "\n",
       "[9527 rows x 17 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = new_df.sample(n = 900) \n",
    "s1 = new_df.sample(n = 900) \n",
    "s2 = new_df.sample(n = 900) \n",
    "s3 = new_df.sample(n = 900) \n",
    "s4 = new_df.sample(n = 900) \n",
    "s5 = new_df.sample(n = 900) \n",
    "s6 = new_df.sample(n = 900) \n",
    "s7 = new_df.sample(n = 900) \n",
    "s8 = new_df.sample(n = 900) \n",
    "s9 = new_df.sample(n = 900) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_train = s0.iloc[:, :-1]\n",
    "s0_test = s0.iloc[:, -1]\n",
    "\n",
    "s1_train = s1.iloc[:, :-1]\n",
    "s1_test = s1.iloc[:, -1]\n",
    "\n",
    "s2_train = s2.iloc[:, :-1]\n",
    "s2_test = s2.iloc[:, -1]\n",
    "\n",
    "s3_train = s3.iloc[:, :-1]\n",
    "s3_test = s3.iloc[:, -1]\n",
    "\n",
    "s4_train = s4.iloc[:, :-1]\n",
    "s4_test = s4.iloc[:, -1]\n",
    "\n",
    "s5_train = s5.iloc[:, :-1]\n",
    "s5_test = s5.iloc[:, -1]\n",
    "\n",
    "s6_train = s6.iloc[:, :-1]\n",
    "s6_test = s6.iloc[:, -1]\n",
    "\n",
    "s7_train = s7.iloc[:, :-1]\n",
    "s7_test = s7.iloc[:, -1]\n",
    "\n",
    "s8_train = s8.iloc[:, :-1]\n",
    "s8_test = s8.iloc[:, -1]\n",
    "\n",
    "s9_train = s9.iloc[:, :-1]\n",
    "s9_test = s9.iloc[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4251     2\n",
       "3261     0\n",
       "9996     6\n",
       "1519     5\n",
       "9781     6\n",
       "        ..\n",
       "4913     2\n",
       "8333     6\n",
       "13079    3\n",
       "365      5\n",
       "4355     2\n",
       "Name: Class, Length: 900, dtype: int32"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "classifier = NuSVC(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n",
      "ValueError: specified nu is infeasible\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.40777778 0.89777778        nan 0.59777778 0.67777778        nan\n",
      " 0.45       0.49555556        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for s1: 0.8977777777777778\n",
      "Best Hyperparameters: {'nu': 0.2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\"kernel\": [\"linear\",\"poly\",\"rbf\"], \n",
    "    \"nu\": [0.1,0.2,0.3]\n",
    "}\n",
    "random_search = RandomizedSearchCV(classifier,param_distributions=param_dist,n_iter=100,scoring='accuracy',random_state=1)\n",
    "random_search.fit(s1_train, s1_test)\n",
    "score1=random_search.best_score_\n",
    "params1=random_search.best_params_\n",
    "print('Best Score for s1: %s' % score1)\n",
    "print('Best Hyperparameters: %s' % params1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n",
      "ValueError: specified nu is infeasible\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.38555556 0.87222222        nan 0.62222222 0.53888889        nan\n",
      " 0.48222222 0.48666667        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for s2: 0.8722222222222223\n",
      "Best Hyperparameters: {'nu': 0.2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(classifier,param_distributions=param_dist,n_iter=100,scoring='accuracy',random_state=1)\n",
    "random_search.fit(s2_train, s2_test)\n",
    "score2=random_search.best_score_\n",
    "params2=random_search.best_params_\n",
    "print('Best Score for s2: %s' % score2)\n",
    "print('Best Hyperparameters: %s' % params2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n",
      "ValueError: specified nu is infeasible\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.45111111 0.81222222        nan 0.59       0.69666667        nan\n",
      " 0.45444444 0.5               nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for s3: 0.8122222222222222\n",
      "Best Hyperparameters: {'nu': 0.2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(classifier,param_distributions=param_dist,n_iter=100,scoring='accuracy',random_state=1)\n",
    "random_search.fit(s3_train, s3_test)\n",
    "score3=random_search.best_score_\n",
    "params3=random_search.best_params_\n",
    "print('Best Score for s3: %s' % score3)\n",
    "print('Best Hyperparameters: %s' % params3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for s4: 0.8788888888888888\n",
      "Best Hyperparameters: {'nu': 0.3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_search = RandomizedSearchCV(classifier,param_distributions=param_dist,n_iter=100,scoring='accuracy',random_state=1)\n",
    "random_search.fit(s4_train, s4_test)\n",
    "score4=random_search.best_score_\n",
    "params4=random_search.best_params_\n",
    "print('Best Score for s4: %s' % score4)\n",
    "print('Best Hyperparameters: %s' % params4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n",
      "ValueError: specified nu is infeasible\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.53222222 0.86777778        nan 0.56888889 0.65              nan\n",
      " 0.42333333 0.53888889        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for s5: 0.8677777777777778\n",
      "Best Hyperparameters: {'nu': 0.2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_search = RandomizedSearchCV(classifier,param_distributions=param_dist,n_iter=100,scoring='accuracy',random_state=1)\n",
    "random_search.fit(s5_train, s5_test)\n",
    "score5=random_search.best_score_\n",
    "params5=random_search.best_params_\n",
    "print('Best Score for s5: %s' % score5)\n",
    "print('Best Hyperparameters: %s' % params5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n",
      "ValueError: specified nu is infeasible\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.43777778 0.85444444        nan 0.50888889 0.56444444        nan\n",
      " 0.49666667 0.47111111        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for s6: 0.8544444444444445\n",
      "Best Hyperparameters: {'nu': 0.2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_search = RandomizedSearchCV(classifier,param_distributions=param_dist,n_iter=100,scoring='accuracy',random_state=1)\n",
    "random_search.fit(s6_train, s6_test)\n",
    "score6=random_search.best_score_\n",
    "params6=random_search.best_params_\n",
    "print('Best Score for s6: %s' % score6)\n",
    "print('Best Hyperparameters: %s' % params6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n",
      "ValueError: specified nu is infeasible\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.44333333 0.89222222        nan 0.58       0.62888889        nan\n",
      " 0.42888889 0.52444444        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for s7: 0.8922222222222222\n",
      "Best Hyperparameters: {'nu': 0.2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_search = RandomizedSearchCV(classifier,param_distributions=param_dist,n_iter=100,scoring='accuracy',random_state=1)\n",
    "random_search.fit(s7_train, s7_test)\n",
    "score7=random_search.best_score_\n",
    "params7=random_search.best_params_\n",
    "print('Best Score for s7: %s' % score7)\n",
    "print('Best Hyperparameters: %s' % params7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for s8: 0.8877777777777778\n",
      "Best Hyperparameters: {'nu': 0.2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_search = RandomizedSearchCV(classifier,param_distributions=param_dist,n_iter=100,scoring='accuracy',random_state=1)\n",
    "random_search.fit(s8_train, s8_test)\n",
    "score8=random_search.best_score_\n",
    "params8=random_search.best_params_\n",
    "print('Best Score for s8: %s' % score8)\n",
    "print('Best Hyperparameters: %s' % params8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for s9: 0.888888888888889\n",
      "Best Hyperparameters: {'nu': 0.2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_search = RandomizedSearchCV(classifier,param_distributions=param_dist,n_iter=100,scoring='accuracy',random_state=1)\n",
    "random_search.fit(s9_train, s9_test)\n",
    "score9=random_search.best_score_\n",
    "params9=random_search.best_params_\n",
    "print('Best Score for s9: %s' % score9)\n",
    "print('Best Hyperparameters: %s' % params9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n",
      "ValueError: specified nu is infeasible\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.39444444 0.81444444        nan 0.57888889 0.62666667        nan\n",
      " 0.44444444 0.50555556        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for s0: 0.8144444444444444\n",
      "Best Hyperparameters: {'nu': 0.2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_search = RandomizedSearchCV(classifier,param_distributions=param_dist,n_iter=100,scoring='accuracy',random_state=1)\n",
    "random_search.fit(s0_train, s0_test)\n",
    "score0=random_search.best_score_\n",
    "params0=random_search.best_params_\n",
    "print('Best Score for s0: %s' % score0)\n",
    "print('Best Hyperparameters: %s' % params0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "xpoints = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "ypoints = np.array([score0,score1,score2,score3,score4,score5,score6,score7,score8,score9])\n",
    "plt.ylabel('Accuracy') \n",
    "plt.xlabel('Sample No.') \n",
    "# plt.title('xlabels() function') \n",
    "plt.plot(xpoints, ypoints)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
